{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmented Lagrangian.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbG8uiCvRolL"
      },
      "source": [
        "## Backtracking Linesearch\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ThAUJAKWmqJ"
      },
      "source": [
        "import numpy as np\r\n",
        "from numpy import linalg as la\r\n",
        "\r\n",
        "\r\n",
        "def backtracking(fun,mu_k,lambda_k,xk,pk,alpha=1,eta=0.01,tau=0.5):\r\n",
        "    \"\"\"\r\n",
        "    Compute the stepsize in line search method\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    a = alpha\r\n",
        "    F1 = eval(fun)(xk+a*pk,mu_k,lambda_k)[0]\r\n",
        "    [F2,G] = eval(fun)(xk,mu_k,lambda_k)\r\n",
        "\r\n",
        "    while (F1 > F2 + eta * a * np.dot(G,pk)):\r\n",
        "        \r\n",
        "        a = tau * a\r\n",
        "        F1 = eval(fun)(xk+a*pk,mu_k,lambda_k)[0]\r\n",
        "        [F2,G] = eval(fun)(xk,mu_k,lambda_k) \r\n",
        "    \r\n",
        "    return a\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "def uncMIN(fun,x0,mu_k,lambda_k,maxit,tol):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    Minimizing twice differentiable function using backtracking-Armijo linesearch\r\n",
        "\r\n",
        "    Input:\r\n",
        "    Fun: string that holds the name of python function.\r\n",
        "    x0: initial guess\r\n",
        "    maxit:  maximum number of iterations allowe\r\n",
        "    printlevel: amount of printout required (first n steps and last n steps)\r\n",
        "    tol: final stopping tolerance\r\n",
        "\r\n",
        "    Outpue:\r\n",
        "    x: final iterate\r\n",
        "    F: functional value on final iterate\r\n",
        "    G: Gradient\r\n",
        "    H: Hessian\r\n",
        "    iter: total number of iterations\r\n",
        "    status: 0 if the tolerance is obtained, 1 otherwise \r\n",
        "    \"\"\" \r\n",
        "    iter_ = 0\r\n",
        "    status = 1\r\n",
        "    print_n = 0\r\n",
        "    x = x0\r\n",
        "    [F0,G0] = eval(fun)(x,mu_k,lambda_k)\r\n",
        "\r\n",
        "    F = F0\r\n",
        "    G = G0\r\n",
        "\r\n",
        "\r\n",
        "    while la.norm(G) > tol * max(1,la.norm(G0)) and iter_ < maxit:\r\n",
        "        iter_ += 1\r\n",
        "        ### search direction ###\r\n",
        "        p = -G \r\n",
        "\r\n",
        "\r\n",
        "        ### stepsize using backtracking-Armijo ###\r\n",
        "        a = backtracking(fun,mu_k,lambda_k,x,p)\r\n",
        "        x = x + a*p \r\n",
        "        [F,G] = eval(fun)(x,mu_k,lambda_k)\r\n",
        "        #print(\"iter:\",iter_,\"xk:\",x,\"fk:\",F,\"gk\",la.norm(G))\r\n",
        "        \r\n",
        "        \r\n",
        "    if (la.norm(G) <= tol * la.norm(G0)):\r\n",
        "        status = 0\r\n",
        "    \r\n",
        "    return  [x,F,G,iter_,status]\r\n",
        "\r\n",
        "\r\n",
        "def test(x):\r\n",
        "    x1 = x[0]\r\n",
        "    x2 = x[1]\r\n",
        "\r\n",
        "    F = 10 * (x2 - x1**2)**2 + (x1-1)**2\r\n",
        "    \r\n",
        "    G1 = -40 * x1 * (x2-x1**2) + 2*(x1-1)\r\n",
        "    G2 = 20 * (x2-x1**2) \r\n",
        "    G = np.array([G1,G2])\r\n",
        "\r\n",
        "    H11 = -40 * (x2 - x1**2 - 2*x1**2) + 2\r\n",
        "    H12 = -40 * x1 \r\n",
        "    H21 = -40 * x1\r\n",
        "    H22 = 20 \r\n",
        "    H = np.array([[H11,H12],[H21,H22]])\r\n",
        "    \r\n",
        "    return [F,G]\r\n",
        "\r\n",
        "def Lag(x,mu_k,lambda_k):\r\n",
        "    x1 = x[0]\r\n",
        "    x2 = x[1]\r\n",
        "\r\n",
        "    F = -5 * x1**2 + x2**2 - lambda_k * (x1-1) + 0.5 * mu_k * (x1-1)**2\r\n",
        "    \r\n",
        "    G1 = -10*x1 -lambda_k + mu_k*(x1-1)\r\n",
        "    G2 = 2*x2\r\n",
        "    G = np.array([G1,G2])\r\n",
        "   \r\n",
        "    return [F,G]\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgYJ0zVdtuD-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b748CVxzRwGN"
      },
      "source": [
        "## Test\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwLgv7_r6OT8"
      },
      "source": [
        "def aug_Lag(tol_k,mu_k,lambda_k,x_k,max_iter):\r\n",
        "    for i in range(max_iter):\r\n",
        "        x_k= uncMIN(\"Lag\",x_k,mu_k,lambda_k,1000,tol_k)[0]\r\n",
        "        lambda_k = lambda_k - mu_k * (x_k[0]**2+x_k[1]**2-1)\r\n",
        "        print(\"lamb\",lambda_k)\r\n",
        "        mu_k = mu_k * 10\r\n",
        "        print(\"mu_k\",mu_k)\r\n",
        "        print(\"iteration:\",i+1,\"x_k: \",x_k)\r\n",
        "        print(\"-----------\")\r\n",
        "    return x_k\r\n",
        "aug_Lag(1e-5,20,1,np.array([2,1]),10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}